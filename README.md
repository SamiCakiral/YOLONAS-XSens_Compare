# YOLO-NAS vs Xsens Comparison on Google Colab

This project aims to compare the performance of YOLO-NAS and Xsens on Google Colab. YOLO-NAS is a state-of-the-art object detection algorithm, while Xsens is a motion capture system. By comparing these two technologies, we can gain insights into their strengths and weaknesses for different applications.

## Table of Contents

- [Introduction](#introduction)
- [Setup](#setup)
- [Usage](#usage)
- [Results](#results)
- [Contributing](#contributing)

## Introduction

In this project, we will provide an overview of YOLO-NAS and Xsens, explaining their key features and use cases. We will also discuss the motivation behind comparing these two technologies and the expected outcomes. This project was conducted as part of the Research and Development mission at IMT Mines Alès, with the goal of conducting a comprehensive comparison of these two technologies. You will be able to see the full report soon. (In French)

## Setup

To replicate the experiments and run the code in this project, follow the steps below:

1. Clone this repository to your local machine.
2. Install the required dependencies by running the following command:
    ```
    pip install -r requirements.txt
    ```
3. Download the necessary datasets and pre-trained models.
4. Set up Google Colab environment and ensure all dependencies are installed.

## Usage

To run the experiments and compare YOLO-NAS and Xsens, follow the steps below:

1. Open the Jupyter notebook `R&D-IMT-Mines-Alès-YOLO-XSENS.ipynb` in Google Colab.
2. Follow the instructions provided in the notebook to load the datasets, train the models, and evaluate their performance.
3. Analyze the results and compare the performance of YOLO-NAS and Xsens based on various metrics.

## Results

The results of the experiments are presented in the notebook `R&D-IMT-Mines-Alès-YOLO-XSENS_Analysis.ipynb`, which includes a tabular format comparing the performance of YOLO-NAS and Xsens on different evaluation metrics such as accuracy, speed, and resource utilization. Visualizations and analysis of the results are also provided to facilitate a comprehensive understanding. And a more detailed analysis of the results can be found in the report.

## Contributing

Contributions to this project are welcome! If you have any ideas, suggestions, or improvements, please feel free to open an issue or submit a pull request. We appreciate your contributions and collaboration.

